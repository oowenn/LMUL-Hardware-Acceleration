{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ce76679-0d7d-43b5-997a-50c171f9d725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3441c78-49b2-4949-a6c5-19e1b038610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 128\n",
    "batch_size_test = 1000\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    datasets.MNIST('.', train=True, download=True, transform=transform),\n",
    "    batch_size=batch_size_train,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    datasets.MNIST('.', train=False, transform=transform),\n",
    "    batch_size=batch_size_test,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb41ad22-db7d-4ca2-bbdb-7f88cdb69716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lmul(a, b, M=7):\n",
    "    \"\"\"\n",
    "    L-MUL approximation based on mantissa/exponent decomposition.\n",
    "    a, b: tensors\n",
    "    M: controls mantissa precision\n",
    "    \"\"\"\n",
    "    a, b = a.float(), b.float()\n",
    "\n",
    "\n",
    "    s1 = torch.sign(a)\n",
    "    s2 = torch.sign(b)\n",
    "    s = s1 * s2\n",
    "\n",
    "\n",
    "    m1, e1 = torch.frexp(torch.abs(a))\n",
    "    m2, e2 = torch.frexp(torch.abs(b))\n",
    "\n",
    "    m1 = 2 * m1 - 1\n",
    "    m2 = 2 * m2 - 1\n",
    "\n",
    " \n",
    "    if M <= 3:\n",
    "        L = M\n",
    "    elif M == 4:\n",
    "        L = 3\n",
    "    else:\n",
    "        L = 4\n",
    "\n",
    "    bias = 1\n",
    "    exponent = e1 + e2 - bias\n",
    "    mantissa = 1 + m1 + m2 + 2**(-L)\n",
    "\n",
    "\n",
    "    carry = (mantissa >= 2).float()\n",
    "    mantissa = torch.where(carry == 1, mantissa / 2, mantissa)\n",
    "    exponent = exponent + carry.long()\n",
    "\n",
    "    out = s * torch.ldexp(mantissa, exponent)\n",
    "    return out\n",
    "\n",
    "\n",
    "def lmul_linear(x, W, b=None, M=7):\n",
    "    \"\"\"\n",
    "    x: [B, D_in]\n",
    "    W: [D_out, D_in]\n",
    "    \"\"\"\n",
    "    B = x.shape[0]\n",
    "    D_out, D_in = W.shape\n",
    "\n",
    "    x_expanded = x.unsqueeze(1).expand(B, D_out, D_in)\n",
    "    W_expanded = W.unsqueeze(0).expand(B, D_out, D_in)\n",
    "\n",
    "    prod = lmul(x_expanded, W_expanded, M=M)\n",
    "    out = prod.sum(dim=2)\n",
    "\n",
    "    if b is not None:\n",
    "        out = out + b\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def lmul_conv2d(x, W, b=None, stride=1, padding=0, M=7):\n",
    "    \"\"\"\n",
    "    x: [B, C_in, H, W]\n",
    "    W: [C_out, C_in, kH, kW]\n",
    "    \"\"\"\n",
    "    B, C_in, H, W_in = x.shape\n",
    "    C_out, C_in_w, kH, kW = W.shape\n",
    "    assert C_in == C_in_w, \"Input channels mismatch\"\n",
    "\n",
    "    patches = F.unfold(x, kernel_size=(kH, kW),\n",
    "                       padding=padding, stride=stride)\n",
    "    K = patches.size(1)\n",
    "    L = patches.size(2)\n",
    "\n",
    "    patches = patches.transpose(1, 2)\n",
    "    W_flat = W.view(C_out, -1)\n",
    "\n",
    "\n",
    "    a = patches.unsqueeze(1) \n",
    "    bW = W_flat.unsqueeze(0).unsqueeze(2) \n",
    "    prod = lmul(a, bW, M=M)  \n",
    "\n",
    "    out = prod.sum(dim=3) \n",
    "\n",
    "    H_out = int((H + 2*padding - kH) / stride + 1)\n",
    "    W_out = int((W_in + 2*padding - kW) / stride + 1)\n",
    "    out = out.view(B, C_out, H_out, W_out)\n",
    "\n",
    "    if b is not None:\n",
    "        out = out + b.view(1, -1, 1, 1)\n",
    "\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450b66cd-ed89-46e1-88b3-b5884f87e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, use_lmul=False, M=7):\n",
    "        super().__init__()\n",
    "        self.use_lmul = use_lmul\n",
    "        self.M = M\n",
    "\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.use_lmul:\n",
    "\n",
    "            x = F.relu(self.conv1(x))\n",
    "            x = F.max_pool2d(x, 2)\n",
    "\n",
    "            x = F.relu(self.conv2(x))\n",
    "            x = F.max_pool2d(x, 2)\n",
    "\n",
    "            x = x.view(x.size(0), -1)\n",
    "\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "\n",
    "        else:\n",
    "\n",
    "            x = lmul_conv2d(x, self.conv1.weight, self.conv1.bias,\n",
    "                            stride=1, padding=1, M=self.M)\n",
    "            x = F.relu(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "\n",
    "            x = lmul_conv2d(x, self.conv2.weight, self.conv2.bias,\n",
    "                            stride=1, padding=1, M=self.M)\n",
    "            x = F.relu(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "\n",
    "            x = x.view(x.size(0), -1)\n",
    "\n",
    "            x = F.relu(lmul_linear(x, self.fc1.weight,\n",
    "                                   self.fc1.bias, M=self.M))\n",
    "            x = lmul_linear(x, self.fc2.weight, self.fc2.bias, M=self.M)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e25b4e8-f7b7-4d64-bb8c-ff0b2f7645c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, loader, epochs=1):\n",
    "    model.train()\n",
    "    for ep in range(epochs):\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = F.nll_loss(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pred = out.argmax(dim=1)\n",
    "            total += y.size(0)\n",
    "            correct += (pred == y).sum().item()\n",
    "\n",
    "        print(f\"Epoch {ep+1}/{epochs} – loss: {loss:.4f}, acc: {correct/total:.4f}\")\n",
    "\n",
    "\n",
    "def test_acc(model, loader):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            pred = out.argmax(dim=1)\n",
    "            total += y.size(0)\n",
    "            correct += (pred == y).sum().item()\n",
    "    return 100.0 * correct / total\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50e3c2e-60af-4ced-b8c1-494f170d46b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 – loss: 0.0910, acc: 0.9283\n",
      "Epoch 2/5 – loss: 0.0621, acc: 0.9811\n",
      "Epoch 3/5 – loss: 0.0205, acc: 0.9868\n",
      "Epoch 4/5 – loss: 0.0271, acc: 0.9893\n",
      "Epoch 5/5 – loss: 0.0493, acc: 0.9913\n",
      "\n",
      "Baseline CNN accuracy (MNIST): 98.94%\n",
      "Baseline total time (train+test): 78.43 s\n"
     ]
    }
   ],
   "source": [
    "baseline_model = CNN(use_lmul=False, M=7).to(device)\n",
    "optimizer = torch.optim.Adam(baseline_model.parameters(), lr=1e-3)\n",
    "\n",
    "start = time.perf_counter()\n",
    "train_model(baseline_model, optimizer, train_loader, epochs=5)\n",
    "baseline_time = time.perf_counter() - start\n",
    "\n",
    "baseline_acc = test_acc(baseline_model, test_loader)\n",
    "\n",
    "print(\"\\nBaseline CNN accuracy (MNIST): {:.2f}%\".format(baseline_acc))\n",
    "print(\"Baseline total time (train+test): {:.2f} s\".format(baseline_time))\n",
    "\n",
    "\n",
    "lmul_model = CNN(use_lmul=True, M=7).to(device)\n",
    "lmul_model.load_state_dict(baseline_model.state_dict())\n",
    "\n",
    "start = time.perf_counter()\n",
    "lmul_acc = test_acc(lmul_model, test_loader)\n",
    "lmul_time = time.perf_counter() - start\n",
    "\n",
    "print(\"\\nLMUL CNN accuracy (MNIST): {:.2f}%\".format(lmul_acc))\n",
    "print(\"LMUL evaluation time: {:.4f} s\".format(lmul_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac99361-151a-4c5d-86b1-681d991249ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
